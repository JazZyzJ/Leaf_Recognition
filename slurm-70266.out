/home/chenzijie/.local/lib/python3.10/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info The read operation timed out
  data = fetch_version_info()
Starting fold 0
{"fold": 0, "epoch": 0, "train_loss": 2.8415605026629707, "train_acc": 0.43841961852861033, "val_loss": 4.910683480571642, "val_acc": 0.16861890493053663, "lr": 0.00019921541278079057}
Fold 0 epoch 0: improved val acc to 0.1686
{"fold": 0, "epoch": 1, "train_loss": 1.605496540381408, "train_acc": 0.7843324250681198, "val_loss": 3.6553272653489826, "val_acc": 0.7000817216017434, "lr": 0.0001968740245322988}
Fold 0 epoch 1: improved val acc to 0.7001
{"fold": 0, "epoch": 2, "train_loss": 1.321914712869504, "train_acc": 0.8784059945504087, "val_loss": 2.0419643896862, "val_acc": 0.8798692454372106, "lr": 0.00019301276034588104}
Fold 0 epoch 2: improved val acc to 0.8799
{"fold": 0, "epoch": 3, "train_loss": 1.190928203598355, "train_acc": 0.9227520435967302, "val_loss": 0.9726672422590388, "val_acc": 0.9242713157177881, "lr": 0.00018769251466436445}
Fold 0 epoch 3: improved val acc to 0.9243
{"fold": 0, "epoch": 4, "train_loss": 1.11022774331901, "train_acc": 0.9438010899182562, "val_loss": 0.48689388977153136, "val_acc": 0.9441569054753474, "lr": 0.0001809971909403073}
Fold 0 epoch 4: improved val acc to 0.9442
{"fold": 0, "epoch": 5, "train_loss": 1.060871052254773, "train_acc": 0.9539509536784742, "val_loss": 0.28195534728100113, "val_acc": 0.9547807137019886, "lr": 0.00017303237842843048}
Fold 0 epoch 5: improved val acc to 0.9548
{"fold": 0, "epoch": 6, "train_loss": 1.0243886881693183, "train_acc": 0.9649182561307902, "val_loss": 0.19567347439505756, "val_acc": 0.962135657858894, "lr": 0.00016392368697999466}
Fold 0 epoch 6: improved val acc to 0.9621
{"fold": 0, "epoch": 7, "train_loss": 0.9943429733167227, "train_acc": 0.9705722070844687, "val_loss": 0.15524776996367312, "val_acc": 0.9673113593026423, "lr": 0.00015381476610041016}
Fold 0 epoch 7: improved val acc to 0.9673
{"fold": 0, "epoch": 8, "train_loss": 0.9640537973320776, "train_acc": 0.9790871934604904, "val_loss": 0.13535179019388338, "val_acc": 0.9692181966766549, "lr": 0.00014286503951072474}
Fold 0 epoch 8: improved val acc to 0.9692
{"fold": 0, "epoch": 9, "train_loss": 0.9474664261620441, "train_acc": 0.9811307901907357, "val_loss": 0.1264278367527075, "val_acc": 0.971397439389812, "lr": 0.00013124719094030727}
Fold 0 epoch 9: improved val acc to 0.9714
{"fold": 0, "epoch": 10, "train_loss": 0.9337355583824969, "train_acc": 0.9832425068119891, "val_loss": 0.12176896155984614, "val_acc": 0.97303187142468, "lr": 0.00011914444080127962}
Fold 0 epoch 10: improved val acc to 0.9730
{"fold": 0, "epoch": 11, "train_loss": 0.9206094731751839, "train_acc": 0.9838555858310627, "val_loss": 0.11957303531421234, "val_acc": 0.97303187142468, "lr": 0.0001067476566931667}
{"fold": 0, "epoch": 12, "train_loss": 0.9075585223348654, "train_acc": 0.9869209809264305, "val_loss": 0.1197639129928041, "val_acc": 0.9743938981204031, "lr": 9.425234330683332e-05}
Fold 0 epoch 12: improved val acc to 0.9744
{"fold": 0, "epoch": 13, "train_loss": 0.898623745740272, "train_acc": 0.9882152588555858, "val_loss": 0.12240691361652022, "val_acc": 0.9746663034595479, "lr": 8.18555591987204e-05}
Fold 0 epoch 13: improved val acc to 0.9747
{"fold": 0, "epoch": 14, "train_loss": 0.8913565691225536, "train_acc": 0.9880108991825614, "val_loss": 0.1259776674245528, "val_acc": 0.9754835194769818, "lr": 6.975280905969276e-05}
Fold 0 epoch 14: improved val acc to 0.9755
{"fold": 0, "epoch": 15, "train_loss": 0.8830372611248526, "train_acc": 0.9904632152588556, "val_loss": 0.1309396849868571, "val_acc": 0.9757559248161264, "lr": 5.813496048927526e-05}
Fold 0 epoch 15: improved val acc to 0.9758
{"fold": 0, "epoch": 16, "train_loss": 0.875189282978588, "train_acc": 0.9920299727520436, "val_loss": 0.13780125805327237, "val_acc": 0.9752111141378371, "lr": 4.7185233899589804e-05}
{"fold": 0, "epoch": 17, "train_loss": 0.8718046002232086, "train_acc": 0.9916212534059945, "val_loss": 0.14498622826694046, "val_acc": 0.9743938981204031, "lr": 3.7076313020005365e-05}
{"fold": 0, "epoch": 18, "train_loss": 0.8678353192370983, "train_acc": 0.9921662125340599, "val_loss": 0.1529326358573114, "val_acc": 0.9741214927812585, "lr": 2.7967621571569573e-05}
{"fold": 0, "epoch": 19, "train_loss": 0.8647301428974162, "train_acc": 0.9922343324250681, "val_loss": 0.16116448468065692, "val_acc": 0.9733042767638246, "lr": 2.0002809059692742e-05}
{"fold": 0, "epoch": 20, "train_loss": 0.860888684478053, "train_acc": 0.9931880108991825, "val_loss": 0.16877060632993401, "val_acc": 0.9727594660855353, "lr": 1.3307485335635575e-05}
{"fold": 0, "epoch": 21, "train_loss": 0.8597105765212784, "train_acc": 0.9934604904632153, "val_loss": 0.17577885945960048, "val_acc": 0.9719422500681013, "lr": 7.987239654118992e-06}
{"fold": 0, "epoch": 22, "train_loss": 0.8585817569607935, "train_acc": 0.9933923705722071, "val_loss": 0.18137111688538618, "val_acc": 0.9722146554072459, "lr": 4.12597546770122e-06}
{"fold": 0, "epoch": 23, "train_loss": 0.8566844848586038, "train_acc": 0.9938010899182561, "val_loss": 0.18669291185451053, "val_acc": 0.9719422500681013, "lr": 1.7845872192094625e-06}
{"fold": 0, "epoch": 24, "train_loss": 0.8570511450559631, "train_acc": 0.9934604904632153, "val_loss": 0.19092254827138483, "val_acc": 0.9708526287115228, "lr": 1e-06}
Saved best model for fold 0 to weights/resnet200d_baseline_fold0.pth
Starting fold 1
{"fold": 1, "epoch": 0, "train_loss": 2.818162212514747, "train_acc": 0.4427792915531335, "val_loss": 4.906909256142512, "val_acc": 0.23154453827295016, "lr": 0.00019921541278079057}
Fold 1 epoch 0: improved val acc to 0.2315
{"fold": 1, "epoch": 1, "train_loss": 1.6071608898750118, "train_acc": 0.7873297002724796, "val_loss": 3.6250035607564746, "val_acc": 0.7357668210296922, "lr": 0.0001968740245322988}
Fold 1 epoch 1: improved val acc to 0.7358
{"fold": 1, "epoch": 2, "train_loss": 1.323233326351935, "train_acc": 0.8799727520435967, "val_loss": 2.040132992600784, "val_acc": 0.8673385998365568, "lr": 0.00019301276034588104}
Fold 1 epoch 2: improved val acc to 0.8673
{"fold": 1, "epoch": 3, "train_loss": 1.20243807501624, "train_acc": 0.9152588555858311, "val_loss": 0.9914169467719756, "val_acc": 0.9294470171615363, "lr": 0.00018769251466436445}
Fold 1 epoch 3: improved val acc to 0.9294
{"fold": 1, "epoch": 4, "train_loss": 1.1198094625888793, "train_acc": 0.9403950953678474, "val_loss": 0.5000203711497495, "val_acc": 0.9526014709888314, "lr": 0.0001809971909403073}
Fold 1 epoch 4: improved val acc to 0.9526
{"fold": 1, "epoch": 5, "train_loss": 1.0653964902139814, "train_acc": 0.953882833787466, "val_loss": 0.29083582870936203, "val_acc": 0.962952873876328, "lr": 0.00017303237842843048}
Fold 1 epoch 5: improved val acc to 0.9630
{"fold": 1, "epoch": 6, "train_loss": 1.0254293985197915, "train_acc": 0.9646457765667575, "val_loss": 0.19569860366296132, "val_acc": 0.9684009806592209, "lr": 0.00016392368697999466}
Fold 1 epoch 6: improved val acc to 0.9684
{"fold": 1, "epoch": 7, "train_loss": 0.9957661659581135, "train_acc": 0.9717983651226159, "val_loss": 0.14803557929226957, "val_acc": 0.9724870607463906, "lr": 0.00015381476610041016}
Fold 1 epoch 7: improved val acc to 0.9725
{"fold": 1, "epoch": 8, "train_loss": 0.9742151600788335, "train_acc": 0.9744550408719346, "val_loss": 0.12392036522223884, "val_acc": 0.976845546172705, "lr": 0.00014286503951072474}
Fold 1 epoch 8: improved val acc to 0.9768
{"fold": 1, "epoch": 9, "train_loss": 0.9547257309713546, "train_acc": 0.9786784741144414, "val_loss": 0.11061118742351116, "val_acc": 0.9773903568509943, "lr": 0.00013124719094030727}
Fold 1 epoch 9: improved val acc to 0.9774
{"fold": 1, "epoch": 10, "train_loss": 0.9345167529680424, "train_acc": 0.9829700272479565, "val_loss": 0.10457939562648819, "val_acc": 0.9790247888858622, "lr": 0.00011914444080127962}
Fold 1 epoch 10: improved val acc to 0.9790
{"fold": 1, "epoch": 11, "train_loss": 0.9225791965258544, "train_acc": 0.9833106267029973, "val_loss": 0.10095220772350104, "val_acc": 0.9792971942250068, "lr": 0.0001067476566931667}
Fold 1 epoch 11: improved val acc to 0.9793
{"fold": 1, "epoch": 12, "train_loss": 0.9095186234819792, "train_acc": 0.9856948228882834, "val_loss": 0.10122647748671998, "val_acc": 0.9792971942250068, "lr": 9.425234330683332e-05}
{"fold": 1, "epoch": 13, "train_loss": 0.8999140895679796, "train_acc": 0.9883514986376022, "val_loss": 0.10359386726402028, "val_acc": 0.9782075728684282, "lr": 8.18555591987204e-05}
{"fold": 1, "epoch": 14, "train_loss": 0.893476378203088, "train_acc": 0.9880108991825614, "val_loss": 0.10755925255266174, "val_acc": 0.9787523835467176, "lr": 6.975280905969276e-05}
{"fold": 1, "epoch": 15, "train_loss": 0.8839774254232401, "train_acc": 0.9899182561307902, "val_loss": 0.11432557661127928, "val_acc": 0.9779351675292836, "lr": 5.813496048927526e-05}
{"fold": 1, "epoch": 16, "train_loss": 0.8782689813372225, "train_acc": 0.9910762942779292, "val_loss": 0.12078493988703103, "val_acc": 0.9782075728684282, "lr": 4.7185233899589804e-05}
{"fold": 1, "epoch": 17, "train_loss": 0.8724069380955085, "train_acc": 0.9907356948228883, "val_loss": 0.1276249643460878, "val_acc": 0.9782075728684282, "lr": 3.7076313020005365e-05}
{"fold": 1, "epoch": 18, "train_loss": 0.8696357149194307, "train_acc": 0.9914850136239782, "val_loss": 0.13497355713470208, "val_acc": 0.9771179515118497, "lr": 2.7967621571569573e-05}
{"fold": 1, "epoch": 19, "train_loss": 0.8649673310547499, "train_acc": 0.9921662125340599, "val_loss": 0.14211451773689282, "val_acc": 0.976028330155271, "lr": 2.0002809059692742e-05}
{"fold": 1, "epoch": 20, "train_loss": 0.8632563629657112, "train_acc": 0.9923024523160763, "val_loss": 0.14822408272594303, "val_acc": 0.9752111141378371, "lr": 1.3307485335635575e-05}
{"fold": 1, "epoch": 21, "train_loss": 0.8603229553238247, "train_acc": 0.9931880108991825, "val_loss": 0.15429717190695602, "val_acc": 0.9746663034595479, "lr": 7.987239654118992e-06}
{"fold": 1, "epoch": 22, "train_loss": 0.8588461049571025, "train_acc": 0.9930517711171662, "val_loss": 0.16039238166895137, "val_acc": 0.9746663034595479, "lr": 4.12597546770122e-06}
{"fold": 1, "epoch": 23, "train_loss": 0.8581221259907091, "train_acc": 0.9934604904632153, "val_loss": 0.16552121849597165, "val_acc": 0.9743938981204031, "lr": 1.7845872192094625e-06}
{"fold": 1, "epoch": 24, "train_loss": 0.8575745012519795, "train_acc": 0.9938010899182561, "val_loss": 0.16965852765702838, "val_acc": 0.9743938981204031, "lr": 1e-06}
Saved best model for fold 1 to weights/resnet200d_baseline_fold1.pth
Starting fold 2
{"fold": 2, "epoch": 0, "train_loss": 2.874140921600508, "train_acc": 0.42772479564032695, "val_loss": 4.912113401422836, "val_acc": 0.26259874693543994, "lr": 0.00019921541278079057}
Fold 2 epoch 0: improved val acc to 0.2626
{"fold": 2, "epoch": 1, "train_loss": 1.6003807510926873, "train_acc": 0.7902588555858311, "val_loss": 3.6434363450513034, "val_acc": 0.7147916099155543, "lr": 0.0001968740245322988}
Fold 2 epoch 1: improved val acc to 0.7148
{"fold": 2, "epoch": 2, "train_loss": 1.3256168723106385, "train_acc": 0.8813351498637603, "val_loss": 2.0414011339438574, "val_acc": 0.8755107600108962, "lr": 0.00019301276034588104}
Fold 2 epoch 2: improved val acc to 0.8755
{"fold": 2, "epoch": 3, "train_loss": 1.193383280587781, "train_acc": 0.9185967302452316, "val_loss": 0.9758464380169201, "val_acc": 0.9275401797875238, "lr": 0.00018769251466436445}
Fold 2 epoch 3: improved val acc to 0.9275
{"fold": 2, "epoch": 4, "train_loss": 1.1152920174988479, "train_acc": 0.9420980926430518, "val_loss": 0.4810324849013378, "val_acc": 0.9466085535276492, "lr": 0.0001809971909403073}
Fold 2 epoch 4: improved val acc to 0.9466
{"fold": 2, "epoch": 5, "train_loss": 1.0651639259478702, "train_acc": 0.9547683923705722, "val_loss": 0.2824474254978739, "val_acc": 0.957504767093435, "lr": 0.00017303237842843048}
Fold 2 epoch 5: improved val acc to 0.9575
{"fold": 2, "epoch": 6, "train_loss": 1.021420120478326, "train_acc": 0.9651907356948229, "val_loss": 0.1931873043505381, "val_acc": 0.9654045219286298, "lr": 0.00016392368697999466}
Fold 2 epoch 6: improved val acc to 0.9654
{"fold": 2, "epoch": 7, "train_loss": 0.994634625080171, "train_acc": 0.9711171662125341, "val_loss": 0.14976221204485954, "val_acc": 0.9689457913375102, "lr": 0.00015381476610041016}
Fold 2 epoch 7: improved val acc to 0.9689
{"fold": 2, "epoch": 8, "train_loss": 0.9708495066341327, "train_acc": 0.9764305177111716, "val_loss": 0.12608770792935986, "val_acc": 0.9719422500681013, "lr": 0.00014286503951072474}
Fold 2 epoch 8: improved val acc to 0.9719
{"fold": 2, "epoch": 9, "train_loss": 0.9501630855516127, "train_acc": 0.979700272479564, "val_loss": 0.11436189738087289, "val_acc": 0.9749387087986925, "lr": 0.00013124719094030727}
Fold 2 epoch 9: improved val acc to 0.9749
{"fold": 2, "epoch": 10, "train_loss": 0.9323003252780405, "train_acc": 0.9825613079019073, "val_loss": 0.1081522647560341, "val_acc": 0.9752111141378371, "lr": 0.00011914444080127962}
Fold 2 epoch 10: improved val acc to 0.9752
{"fold": 2, "epoch": 11, "train_loss": 0.9228959746516693, "train_acc": 0.9835149863760217, "val_loss": 0.10632123177892926, "val_acc": 0.9746663034595479, "lr": 0.0001067476566931667}
{"fold": 2, "epoch": 12, "train_loss": 0.9096920474348665, "train_acc": 0.9863760217983651, "val_loss": 0.10691052046889864, "val_acc": 0.9776627621901389, "lr": 9.425234330683332e-05}
Fold 2 epoch 12: improved val acc to 0.9777
{"fold": 2, "epoch": 13, "train_loss": 0.8991148451368556, "train_acc": 0.9886239782016348, "val_loss": 0.10906191828407731, "val_acc": 0.9779351675292836, "lr": 8.18555591987204e-05}
Fold 2 epoch 13: improved val acc to 0.9779
{"fold": 2, "epoch": 14, "train_loss": 0.888978038107017, "train_acc": 0.9893051771117166, "val_loss": 0.11368141257772651, "val_acc": 0.9773903568509943, "lr": 6.975280905969276e-05}
{"fold": 2, "epoch": 15, "train_loss": 0.8820314998197946, "train_acc": 0.9901226158038147, "val_loss": 0.1183166814695519, "val_acc": 0.9779351675292836, "lr": 5.813496048927526e-05}
{"fold": 2, "epoch": 16, "train_loss": 0.8777419867242714, "train_acc": 0.9903269754768392, "val_loss": 0.12451616941754093, "val_acc": 0.9773903568509943, "lr": 4.7185233899589804e-05}
{"fold": 2, "epoch": 17, "train_loss": 0.8720609407983618, "train_acc": 0.9918256130790191, "val_loss": 0.13088753660549685, "val_acc": 0.976028330155271, "lr": 3.7076313020005365e-05}
{"fold": 2, "epoch": 18, "train_loss": 0.8678716893741805, "train_acc": 0.9919618528610354, "val_loss": 0.13800788644799677, "val_acc": 0.9757559248161264, "lr": 2.7967621571569573e-05}
{"fold": 2, "epoch": 19, "train_loss": 0.8650990251624292, "train_acc": 0.9923024523160763, "val_loss": 0.14555986664196802, "val_acc": 0.9757559248161264, "lr": 2.0002809059692742e-05}
{"fold": 2, "epoch": 20, "train_loss": 0.8619587429862581, "train_acc": 0.9927792915531335, "val_loss": 0.15268823010651625, "val_acc": 0.9746663034595479, "lr": 1.3307485335635575e-05}
{"fold": 2, "epoch": 21, "train_loss": 0.8594009391293539, "train_acc": 0.9937329700272479, "val_loss": 0.15954155428626823, "val_acc": 0.9746663034595479, "lr": 7.987239654118992e-06}
{"fold": 2, "epoch": 22, "train_loss": 0.858751908342585, "train_acc": 0.9926430517711171, "val_loss": 0.165718508159244, "val_acc": 0.9746663034595479, "lr": 4.12597546770122e-06}
{"fold": 2, "epoch": 23, "train_loss": 0.8578327527812781, "train_acc": 0.9927111716621253, "val_loss": 0.1711287650509804, "val_acc": 0.9738490874421138, "lr": 1.7845872192094625e-06}
{"fold": 2, "epoch": 24, "train_loss": 0.8573077295066875, "train_acc": 0.9933923705722071, "val_loss": 0.1757971978591853, "val_acc": 0.9735766821029692, "lr": 1e-06}
Saved best model for fold 2 to weights/resnet200d_baseline_fold2.pth
Starting fold 3
{"fold": 3, "epoch": 0, "train_loss": 2.810751573461278, "train_acc": 0.4491144414168937, "val_loss": 4.900464734329515, "val_acc": 0.21362397820163487, "lr": 0.00019921541278079057}
Fold 3 epoch 0: improved val acc to 0.2136
{"fold": 3, "epoch": 1, "train_loss": 1.5880043315627594, "train_acc": 0.7934604904632152, "val_loss": 3.6006629715173704, "val_acc": 0.7226158038147139, "lr": 0.0001968740245322988}
Fold 3 epoch 1: improved val acc to 0.7226
{"fold": 3, "epoch": 2, "train_loss": 1.3183549897547313, "train_acc": 0.8818119891008175, "val_loss": 1.99574430157768, "val_acc": 0.8673024523160763, "lr": 0.00019301276034588104}
Fold 3 epoch 2: improved val acc to 0.8673
{"fold": 3, "epoch": 3, "train_loss": 1.1865616252376858, "train_acc": 0.9211852861035422, "val_loss": 0.9624352136814627, "val_acc": 0.923433242506812, "lr": 0.00018769251466436445}
Fold 3 epoch 3: improved val acc to 0.9234
{"fold": 3, "epoch": 4, "train_loss": 1.1177386470321737, "train_acc": 0.9401907356948229, "val_loss": 0.47811401890798877, "val_acc": 0.9438692098092643, "lr": 0.0001809971909403073}
Fold 3 epoch 4: improved val acc to 0.9439
{"fold": 3, "epoch": 5, "train_loss": 1.063510727102815, "train_acc": 0.9553133514986376, "val_loss": 0.27927364888892836, "val_acc": 0.9572207084468665, "lr": 0.00017303237842843048}
Fold 3 epoch 5: improved val acc to 0.9572
{"fold": 3, "epoch": 6, "train_loss": 1.0193476908213437, "train_acc": 0.9667574931880109, "val_loss": 0.19254845137167367, "val_acc": 0.9637602179836512, "lr": 0.00016392368697999466}
Fold 3 epoch 6: improved val acc to 0.9638
{"fold": 3, "epoch": 7, "train_loss": 0.9945881728580277, "train_acc": 0.9725476839237057, "val_loss": 0.14983359159906814, "val_acc": 0.9683923705722071, "lr": 0.00015381476610041016}
Fold 3 epoch 7: improved val acc to 0.9684
{"fold": 3, "epoch": 8, "train_loss": 0.9675114283444771, "train_acc": 0.9764305177111716, "val_loss": 0.1286934400855358, "val_acc": 0.9724795640326975, "lr": 0.00014286503951072474}
Fold 3 epoch 8: improved val acc to 0.9725
{"fold": 3, "epoch": 9, "train_loss": 0.9490615102510687, "train_acc": 0.9802452316076294, "val_loss": 0.11694837915799923, "val_acc": 0.9730245231607629, "lr": 0.00013124719094030727}
Fold 3 epoch 9: improved val acc to 0.9730
{"fold": 3, "epoch": 10, "train_loss": 0.9357229168798358, "train_acc": 0.9814713896457765, "val_loss": 0.11108533460697621, "val_acc": 0.9771117166212534, "lr": 0.00011914444080127962}
Fold 3 epoch 10: improved val acc to 0.9771
{"fold": 3, "epoch": 11, "train_loss": 0.9194114423577727, "train_acc": 0.9856948228882834, "val_loss": 0.11033294996302524, "val_acc": 0.9771117166212534, "lr": 0.0001067476566931667}
{"fold": 3, "epoch": 12, "train_loss": 0.9086568206467486, "train_acc": 0.9854223433242507, "val_loss": 0.1108061693547857, "val_acc": 0.9776566757493188, "lr": 9.425234330683332e-05}
Fold 3 epoch 12: improved val acc to 0.9777
{"fold": 3, "epoch": 13, "train_loss": 0.8970663677769071, "train_acc": 0.9885558583106268, "val_loss": 0.11307683200943372, "val_acc": 0.9768392370572208, "lr": 8.18555591987204e-05}
{"fold": 3, "epoch": 14, "train_loss": 0.891445867404626, "train_acc": 0.9882152588555858, "val_loss": 0.1167666471499838, "val_acc": 0.9776566757493188, "lr": 6.975280905969276e-05}
{"fold": 3, "epoch": 15, "train_loss": 0.8840549839290026, "train_acc": 0.9891689373297002, "val_loss": 0.12226881987798441, "val_acc": 0.9776566757493188, "lr": 5.813496048927526e-05}
{"fold": 3, "epoch": 16, "train_loss": 0.8765040002661765, "train_acc": 0.9907356948228883, "val_loss": 0.12781112040989406, "val_acc": 0.976566757493188, "lr": 4.7185233899589804e-05}
{"fold": 3, "epoch": 17, "train_loss": 0.8706514040195974, "train_acc": 0.9918937329700273, "val_loss": 0.1341756418956398, "val_acc": 0.97574931880109, "lr": 3.7076313020005365e-05}
{"fold": 3, "epoch": 18, "train_loss": 0.8681938131758563, "train_acc": 0.9915531335149864, "val_loss": 0.14086752658156673, "val_acc": 0.9752043596730245, "lr": 2.7967621571569573e-05}
{"fold": 3, "epoch": 19, "train_loss": 0.8646550118111135, "train_acc": 0.9927792915531335, "val_loss": 0.148669186340041, "val_acc": 0.9754768392370572, "lr": 2.0002809059692742e-05}
{"fold": 3, "epoch": 20, "train_loss": 0.8620259976192132, "train_acc": 0.9925068119891008, "val_loss": 0.15630217342350725, "val_acc": 0.9749318801089918, "lr": 1.3307485335635575e-05}
{"fold": 3, "epoch": 21, "train_loss": 0.8603201015443828, "train_acc": 0.9926430517711171, "val_loss": 0.16397141231178264, "val_acc": 0.9741144414168937, "lr": 7.987239654118992e-06}
{"fold": 3, "epoch": 22, "train_loss": 0.8593833653088812, "train_acc": 0.9929836512261581, "val_loss": 0.17077465114216714, "val_acc": 0.9732970027247957, "lr": 4.12597546770122e-06}
{"fold": 3, "epoch": 23, "train_loss": 0.8582302368954027, "train_acc": 0.9935286103542235, "val_loss": 0.17659110668082328, "val_acc": 0.9724795640326975, "lr": 1.7845872192094625e-06}
{"fold": 3, "epoch": 24, "train_loss": 0.8571934077655262, "train_acc": 0.9937329700272479, "val_loss": 0.1814961164458896, "val_acc": 0.9716621253405995, "lr": 1e-06}
Saved best model for fold 3 to weights/resnet200d_baseline_fold3.pth
Starting fold 4
{"fold": 4, "epoch": 0, "train_loss": 2.7644951814526757, "train_acc": 0.4566076294277929, "val_loss": 4.891536758641132, "val_acc": 0.22724795640326975, "lr": 0.00019921541278079057}
Fold 4 epoch 0: improved val acc to 0.2272
{"fold": 4, "epoch": 1, "train_loss": 1.577429564057644, "train_acc": 0.7947547683923706, "val_loss": 3.5535249095521766, "val_acc": 0.7525885558583106, "lr": 0.0001968740245322988}
Fold 4 epoch 1: improved val acc to 0.7526
{"fold": 4, "epoch": 2, "train_loss": 1.316538011540509, "train_acc": 0.8801771117166213, "val_loss": 1.9107110026097103, "val_acc": 0.8762942779291553, "lr": 0.00019301276034588104}
Fold 4 epoch 2: improved val acc to 0.8763
{"fold": 4, "epoch": 3, "train_loss": 1.187916089176157, "train_acc": 0.9240463215258855, "val_loss": 0.8896957827848699, "val_acc": 0.9228882833787466, "lr": 0.00018769251466436445}
Fold 4 epoch 3: improved val acc to 0.9229
{"fold": 4, "epoch": 4, "train_loss": 1.112067737241532, "train_acc": 0.9432561307901908, "val_loss": 0.44921507060690213, "val_acc": 0.9444141689373297, "lr": 0.0001809971909403073}
Fold 4 epoch 4: improved val acc to 0.9444
{"fold": 4, "epoch": 5, "train_loss": 1.0584463195190117, "train_acc": 0.9583106267029973, "val_loss": 0.2690365247326911, "val_acc": 0.95858310626703, "lr": 0.00017303237842843048}
Fold 4 epoch 5: improved val acc to 0.9586
{"fold": 4, "epoch": 6, "train_loss": 1.0206010920800046, "train_acc": 0.966825613079019, "val_loss": 0.19278813458024968, "val_acc": 0.964850136239782, "lr": 0.00016392368697999466}
Fold 4 epoch 6: improved val acc to 0.9649
{"fold": 4, "epoch": 7, "train_loss": 0.9952813730577682, "train_acc": 0.9726158038147139, "val_loss": 0.15514661379219402, "val_acc": 0.9670299727520436, "lr": 0.00015381476610041016}
Fold 4 epoch 7: improved val acc to 0.9670
{"fold": 4, "epoch": 8, "train_loss": 0.9714943048414807, "train_acc": 0.9754768392370572, "val_loss": 0.1359835060765048, "val_acc": 0.9692098092643052, "lr": 0.00014286503951072474}
Fold 4 epoch 8: improved val acc to 0.9692
{"fold": 4, "epoch": 9, "train_loss": 0.9483826441076211, "train_acc": 0.9804495912806539, "val_loss": 0.12682663893342344, "val_acc": 0.9692098092643052, "lr": 0.00013124719094030727}
{"fold": 4, "epoch": 10, "train_loss": 0.9326673006166879, "train_acc": 0.9844686648501363, "val_loss": 0.12319238688542992, "val_acc": 0.9708446866485013, "lr": 0.00011914444080127962}
Fold 4 epoch 10: improved val acc to 0.9708
{"fold": 4, "epoch": 11, "train_loss": 0.9198025594615157, "train_acc": 0.986716621253406, "val_loss": 0.12130197093134355, "val_acc": 0.9719346049046321, "lr": 0.0001067476566931667}
Fold 4 epoch 11: improved val acc to 0.9719
{"fold": 4, "epoch": 12, "train_loss": 0.9073302745819092, "train_acc": 0.987874659400545, "val_loss": 0.12093639099914631, "val_acc": 0.973841961852861, "lr": 9.425234330683332e-05}
Fold 4 epoch 12: improved val acc to 0.9738
{"fold": 4, "epoch": 13, "train_loss": 0.8998412804642555, "train_acc": 0.987874659400545, "val_loss": 0.12429821712931755, "val_acc": 0.973841961852861, "lr": 8.18555591987204e-05}
{"fold": 4, "epoch": 14, "train_loss": 0.8902524454067449, "train_acc": 0.9893051771117166, "val_loss": 0.12874962775397042, "val_acc": 0.9722070844686649, "lr": 6.975280905969276e-05}
{"fold": 4, "epoch": 15, "train_loss": 0.8823489753361944, "train_acc": 0.991008174386921, "val_loss": 0.13386701803644283, "val_acc": 0.9727520435967303, "lr": 5.813496048927526e-05}
{"fold": 4, "epoch": 16, "train_loss": 0.8771228162729123, "train_acc": 0.9912806539509537, "val_loss": 0.14057775590700738, "val_acc": 0.9719346049046321, "lr": 4.7185233899589804e-05}
{"fold": 4, "epoch": 17, "train_loss": 0.8711323613691719, "train_acc": 0.9923024523160763, "val_loss": 0.14906958316424887, "val_acc": 0.9719346049046321, "lr": 3.7076313020005365e-05}
{"fold": 4, "epoch": 18, "train_loss": 0.8681784605135385, "train_acc": 0.9918256130790191, "val_loss": 0.15703870875390413, "val_acc": 0.9719346049046321, "lr": 2.7967621571569573e-05}
{"fold": 4, "epoch": 19, "train_loss": 0.8644438101420285, "train_acc": 0.9928474114441417, "val_loss": 0.16406070657419575, "val_acc": 0.9716621253405995, "lr": 2.0002809059692742e-05}
{"fold": 4, "epoch": 20, "train_loss": 0.8622857373157055, "train_acc": 0.9923705722070845, "val_loss": 0.17106655657453823, "val_acc": 0.9708446866485013, "lr": 1.3307485335635575e-05}
{"fold": 4, "epoch": 21, "train_loss": 0.8601394598750393, "train_acc": 0.9929155313351499, "val_loss": 0.1779795948872774, "val_acc": 0.9705722070844687, "lr": 7.987239654118992e-06}
{"fold": 4, "epoch": 22, "train_loss": 0.8578791674866014, "train_acc": 0.9931198910081744, "val_loss": 0.18442321016531874, "val_acc": 0.9708446866485013, "lr": 4.12597546770122e-06}
{"fold": 4, "epoch": 23, "train_loss": 0.8574667716221199, "train_acc": 0.9931198910081744, "val_loss": 0.1901117506931848, "val_acc": 0.9692098092643052, "lr": 1.7845872192094625e-06}
{"fold": 4, "epoch": 24, "train_loss": 0.8569455526505244, "train_acc": 0.9937329700272479, "val_loss": 0.1948375596053269, "val_acc": 0.9686648501362398, "lr": 1e-06}
Saved best model for fold 4 to weights/resnet200d_baseline_fold4.pth
Saved OOF predictions to oof/resnet200d_baseline_oof.npy
CV Accuracy: 0.9769
